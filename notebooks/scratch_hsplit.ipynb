{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-18T21:00:47.026866Z",
     "start_time": "2021-06-18T21:00:46.992928Z"
    }
   },
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "import re\n",
    "\n",
    "from htools import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-18T21:07:34.220779Z",
     "start_time": "2021-06-18T21:07:34.149115Z"
    }
   },
   "outputs": [],
   "source": [
    "def hsplit(text, sep, group=True, attach=True):\n",
    "    \"\"\"Flexible string splitting that retains the delimiter rather, unlike\n",
    "    the built-in str.split() method.\n",
    "    \n",
    "    Parameters\n",
    "    -----------\n",
    "    text: str\n",
    "        The input text to be split.\n",
    "    sep: str\n",
    "        The delimiter to be split on.\n",
    "    group: bool\n",
    "        Specifies whether to group consecutive delimiters together (True),\n",
    "        or to separate them (False).\n",
    "    attach: bool\n",
    "        Specifies whether to attach the delimiter to the string that preceeds \n",
    "        it (True), or to detach it so it appears in the output list as its own \n",
    "        item (False).\n",
    "    \n",
    "    Returns\n",
    "    --------\n",
    "    list[str]\n",
    "    \n",
    "    Examples\n",
    "    ---------\n",
    "    text = \"Score -- Giants win 6-5\"\n",
    "    sep = '-'\n",
    "    \n",
    "    # Case 0.1: Delimiters are grouped together and attached to the preceding \n",
    "    word.\n",
    "    >> hsplit(text, sep, group=True, attach=True)\n",
    "    >> ['Score --', ' Giants win 6-', '5']\n",
    "    \n",
    "    # Case 0.2: Delimiters are grouped together but are detached from the \n",
    "    preceding word, instead appearing as their own item in the output list.\n",
    "    >> hsplit(text, sep, group=True, attach=False)\n",
    "    >> ['Score ', '--', ' Giants win 6', '-', '5']\n",
    "    \n",
    "    Case 1.1: Delimiters are retained and attached to the preceding string. \n",
    "    If the delimiter occurs multiple times consecutively, only the first \n",
    "    occurrence is attached, and the rest appear as individual items in the \n",
    "    output list.\n",
    "    >> hsplit(text, sep, group=False, attach=True)\n",
    "    >> ['Score -', '-', ' Giants win 6-', '5']\n",
    "    \n",
    "    # Case 1.2: Delimiters are retained but are detached from the preceding\n",
    "    string.\n",
    "    It appears as its own item in the output list.\n",
    "    >> hsplit(text, sep, group=False, attach=False)\n",
    "    >> ['Score ', '-', '-', ' Giants win 6', '-', '5']\n",
    "    \"\"\"\n",
    "    sep_re = re.escape(sep)\n",
    "    regex = f'[^{sep_re}]*{sep_re}*'        \n",
    "    \n",
    "    ##########################################################################\n",
    "    # Case 0: Consecutive delimiters are grouped together.\n",
    "    ##########################################################################\n",
    "    if group:\n",
    "        # Subcase 0.1\n",
    "        if attach:\n",
    "            return [word for word in re.findall(regex, text)][:-1]\n",
    "        \n",
    "        # Subcase 0.2\n",
    "        else:\n",
    "            return [word for word in re.split(f'({sep_re}+)', text) if word]\n",
    "    \n",
    "    ##########################################################################\n",
    "    # Case 1: Consecutive delimiters are NOT grouped together.\n",
    "    ##########################################################################\n",
    "    words = text.split(sep)\n",
    "\n",
    "    # Subcase 1.1\n",
    "    if attach:\n",
    "        return [word for word in re.findall(regex[:-1]+'?', text) if word]\n",
    "    \n",
    "    # Subcase 1.2\n",
    "    return [word for word in chain(*zip(words, [sep]*len(words))) if word][:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-18T21:07:34.338463Z",
     "start_time": "2021-06-18T21:07:34.307588Z"
    }
   },
   "outputs": [],
   "source": [
    "def sticky_split(text, sep, **kwargs):\n",
    "    \"\"\"Basically a functioning version of htools.hsplit with group=True and\n",
    "    attach=True. Realized that doesn't work when sep contains special\n",
    "    characters.\n",
    "    \n",
    "    Note: accepting kwargs is temporary for compatibility w/ test func\n",
    "    interface.\n",
    "    \"\"\"\n",
    "    res = []\n",
    "    toks = text.split(sep)\n",
    "    max_idx = len(toks) - 1\n",
    "    for i, tok in enumerate(toks):\n",
    "        if tok:\n",
    "            if i < max_idx: tok += sep\n",
    "            res.append(tok)\n",
    "        elif i < max_idx:\n",
    "            if res:\n",
    "                res[-1] += sep\n",
    "            else:\n",
    "                res.append(sep)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-18T21:07:34.515912Z",
     "start_time": "2021-06-18T21:07:34.490001Z"
    }
   },
   "outputs": [],
   "source": [
    "def test_output(tests, sep, fn=hsplit, **kwargs):\n",
    "    for test in tests:\n",
    "        print(test)\n",
    "        print('STANDARD:', test.split(sep))\n",
    "        print('H:', fn(test, sep, **kwargs), end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-18T21:07:34.853852Z",
     "start_time": "2021-06-18T21:07:34.827668Z"
    }
   },
   "outputs": [],
   "source": [
    "text1 = 'I*went to the store* yesterday after* work*to*see* the walrus and it walked slowly* over to me* and sat.'\n",
    "text2 = '*I went*to *the store and* sat next to the window*'\n",
    "text3 = '**I went*to **the store and*** sat next to the window**'\n",
    "\n",
    "texts = [text1, text2, text3]\n",
    "sep = '*'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-18T21:07:35.312864Z",
     "start_time": "2021-06-18T21:07:35.288824Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I*went to the store* yesterday after* work*to*see* the walrus and it walked slowly* over to me* and sat.\n",
      "*I went*to *the store and* sat next to the window*\n",
      "**I went*to **the store and*** sat next to the window**\n"
     ]
    }
   ],
   "source": [
    "for text in texts:\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-18T21:07:35.472036Z",
     "start_time": "2021-06-18T21:07:35.447896Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I*went to the store* yesterday after* work*to*see* the walrus and it walked slowly* over to me* and sat.\n",
      "STANDARD: ['I', 'went to the store', ' yesterday after', ' work', 'to', 'see', ' the walrus and it walked slowly', ' over to me', ' and sat.']\n",
      "H: ['I*', 'went to the store*', ' yesterday after*', ' work*', 'to*', 'see*', ' the walrus and it walked slowly*', ' over to me*', ' and sat.']\n",
      "\n",
      "*I went*to *the store and* sat next to the window*\n",
      "STANDARD: ['', 'I went', 'to ', 'the store and', ' sat next to the window', '']\n",
      "H: ['*', 'I went*', 'to *', 'the store and*', ' sat next to the window*']\n",
      "\n",
      "**I went*to **the store and*** sat next to the window**\n",
      "STANDARD: ['', '', 'I went', 'to ', '', 'the store and', '', '', ' sat next to the window', '', '']\n",
      "H: ['**', 'I went*', 'to **', 'the store and***', ' sat next to the window**']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_output(texts, sep, group=True, attach=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-18T21:07:35.819800Z",
     "start_time": "2021-06-18T21:07:35.789090Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I*went to the store* yesterday after* work*to*see* the walrus and it walked slowly* over to me* and sat.\n",
      "STANDARD: ['I', 'went to the store', ' yesterday after', ' work', 'to', 'see', ' the walrus and it walked slowly', ' over to me', ' and sat.']\n",
      "H: ['I*', 'went to the store*', ' yesterday after*', ' work*', 'to*', 'see*', ' the walrus and it walked slowly*', ' over to me*', ' and sat.']\n",
      "\n",
      "*I went*to *the store and* sat next to the window*\n",
      "STANDARD: ['', 'I went', 'to ', 'the store and', ' sat next to the window', '']\n",
      "H: ['*', 'I went*', 'to *', 'the store and*', ' sat next to the window*']\n",
      "\n",
      "**I went*to **the store and*** sat next to the window**\n",
      "STANDARD: ['', '', 'I went', 'to ', '', 'the store and', '', '', ' sat next to the window', '', '']\n",
      "H: ['**', 'I went*', 'to **', 'the store and***', ' sat next to the window**']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_output(texts, sep, fn=sticky_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-18T21:07:36.025806Z",
     "start_time": "2021-06-18T21:07:36.000097Z"
    }
   },
   "outputs": [],
   "source": [
    "# Checking that new func sticky_split is equivalent to hsplit case 1 before\n",
    "# testing w/ seps w/ special chars.\n",
    "def compare_split_fns(texts, sep):\n",
    "    for i, text in enumerate(texts):\n",
    "        hs = hsplit(text, sep)\n",
    "        ss = sticky_split(text, sep)\n",
    "        try:\n",
    "            assert hs == ss\n",
    "            print(f'{i}: same')\n",
    "        except:\n",
    "            print(f'{i}: DIFF')\n",
    "            print('hs:', hs)\n",
    "            print('ss:', ss)\n",
    "        print(spacer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-18T21:07:36.448285Z",
     "start_time": "2021-06-18T21:07:36.423985Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: same\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "1: same\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "2: same\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "compare_split_fns(texts, sep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-18T21:07:36.926270Z",
     "start_time": "2021-06-18T21:07:36.899627Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'I\\n\\rwent to the store\\n\\r yesterday after\\n\\r work\\n\\rto\\n\\rsee\\n\\r the walrus and it walked slowly\\n\\r over to me\\n\\r and sat.'\n",
      "'\\n\\rI went\\n\\rto \\n\\rthe store and\\n\\r sat next to the window\\n\\r'\n",
      "'\\n\\r\\n\\rI went\\n\\rto \\n\\r\\n\\rthe store and\\n\\r\\n\\r\\n\\r sat next to the window\\n\\r\\n\\r'\n"
     ]
    }
   ],
   "source": [
    "texts_special = [t.replace('*', '\\n\\r') for t in texts]\n",
    "for t in texts_special:\n",
    "    print(repr(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-18T21:07:37.373238Z",
     "start_time": "2021-06-18T21:07:37.325415Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: DIFF\n",
      "hs: ['I\\n\\r', 'went to the store\\n\\r', ' yesterday after\\n\\r', ' work\\n\\r', 'to\\n\\r', 'see\\n\\r', ' the walrus and it walked slowly\\n\\r']\n",
      "ss: ['I\\n\\r', 'went to the store\\n\\r', ' yesterday after\\n\\r', ' work\\n\\r', 'to\\n\\r', 'see\\n\\r', ' the walrus and it walked slowly\\n\\r', ' over to me\\n\\r', ' and sat.']\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "1: DIFF\n",
      "hs: ['\\n\\r', 'I went\\n\\r', 'to \\n\\r', 'the store and\\n\\r']\n",
      "ss: ['\\n\\r', 'I went\\n\\r', 'to \\n\\r', 'the store and\\n\\r', ' sat next to the window\\n\\r']\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "2: DIFF\n",
      "hs: ['\\n\\r', '\\n\\r', 'I went\\n\\r', 'to \\n\\r', '\\n\\r', 'the store and\\n\\r', '\\n\\r', '\\n\\r', ' sat next to the window\\n\\r']\n",
      "ss: ['\\n\\r\\n\\r', 'I went\\n\\r', 'to \\n\\r\\n\\r', 'the store and\\n\\r\\n\\r\\n\\r', ' sat next to the window\\n\\r\\n\\r']\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "compare_split_fns(texts_special, '\\n\\r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-18T21:01:38.045067Z",
     "start_time": "2021-06-18T21:01:37.988572Z"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "sticky_split() missing 1 required positional argument: 'sep'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-f0248e324338>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msticky_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts_special\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: sticky_split() missing 1 required positional argument: 'sep'"
     ]
    }
   ],
   "source": [
    "sticky_split(texts_special[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-13T05:51:59.649774Z",
     "start_time": "2019-08-13T05:51:59.619447Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I*went to the store* yesterday after* work*to*see* the walrus and it walked slowly* over to me* and sat.\n",
      "STANDARD: ['I', 'went to the store', ' yesterday after', ' work', 'to', 'see', ' the walrus and it walked slowly', ' over to me', ' and sat.']\n",
      "H: ['I', '*', 'went to the store', '*', ' yesterday after', '*', ' work', '*', 'to', '*', 'see', '*', ' the walrus and it walked slowly', '*', ' over to me', '*', ' and sat.']\n",
      "\n",
      "*I went*to *the store and* sat next to the window*\n",
      "STANDARD: ['', 'I went', 'to ', 'the store and', ' sat next to the window', '']\n",
      "H: ['*', 'I went', '*', 'to ', '*', 'the store and', '*', ' sat next to the window', '*']\n",
      "\n",
      "**I went*to **the store and*** sat next to the window**\n",
      "STANDARD: ['', '', 'I went', 'to ', '', 'the store and', '', '', ' sat next to the window', '', '']\n",
      "H: ['**', 'I went', '*', 'to ', '**', 'the store and', '***', ' sat next to the window', '**']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_output(texts, sep, group=True, attach=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-13T05:51:59.685223Z",
     "start_time": "2019-08-13T05:51:59.666834Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I*went to the store* yesterday after* work*to*see* the walrus and it walked slowly* over to me* and sat.\n",
      "STANDARD: ['I', 'went to the store', ' yesterday after', ' work', 'to', 'see', ' the walrus and it walked slowly', ' over to me', ' and sat.']\n",
      "H: ['I*', 'went to the store*', ' yesterday after*', ' work*', 'to*', 'see*', ' the walrus and it walked slowly*', ' over to me*', ' and sat.']\n",
      "\n",
      "*I went*to *the store and* sat next to the window*\n",
      "STANDARD: ['', 'I went', 'to ', 'the store and', ' sat next to the window', '']\n",
      "H: ['*', 'I went*', 'to *', 'the store and*', ' sat next to the window*']\n",
      "\n",
      "**I went*to **the store and*** sat next to the window**\n",
      "STANDARD: ['', '', 'I went', 'to ', '', 'the store and', '', '', ' sat next to the window', '', '']\n",
      "H: ['*', '*', 'I went*', 'to *', '*', 'the store and*', '*', '*', ' sat next to the window*', '*']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_output(texts, sep, group=False, attach=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-13T05:51:59.698200Z",
     "start_time": "2019-08-13T05:51:59.689091Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I*went to the store* yesterday after* work*to*see* the walrus and it walked slowly* over to me* and sat.\n",
      "STANDARD: ['I', 'went to the store', ' yesterday after', ' work', 'to', 'see', ' the walrus and it walked slowly', ' over to me', ' and sat.']\n",
      "H: ['I', '*', 'went to the store', '*', ' yesterday after', '*', ' work', '*', 'to', '*', 'see', '*', ' the walrus and it walked slowly', '*', ' over to me', '*', ' and sat.']\n",
      "\n",
      "*I went*to *the store and* sat next to the window*\n",
      "STANDARD: ['', 'I went', 'to ', 'the store and', ' sat next to the window', '']\n",
      "H: ['*', 'I went', '*', 'to ', '*', 'the store and', '*', ' sat next to the window', '*']\n",
      "\n",
      "**I went*to **the store and*** sat next to the window**\n",
      "STANDARD: ['', '', 'I went', 'to ', '', 'the store and', '', '', ' sat next to the window', '', '']\n",
      "H: ['*', '*', 'I went', '*', 'to ', '*', '*', 'the store and', '*', '*', '*', ' sat next to the window', '*', '*']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_output(texts, sep, group=False, attach=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-13T05:51:59.712686Z",
     "start_time": "2019-08-13T05:51:59.700417Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'went to the store', ' yesterday after', ' work', 'to', 'see', ' the walrus and it walked slowly', ' over to me', ' and sat.']\n",
      "\n",
      "['', 'I went', 'to ', 'the store and', ' sat next to the window', '']\n",
      "\n",
      "['', '', 'I went', 'to ', '', 'the store and', '', '', ' sat next to the window', '', '']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for text in texts:\n",
    "    print(text.split(sep), end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-13T05:51:59.724794Z",
     "start_time": "2019-08-13T05:51:59.715255Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('../data/lines100.txt', 'r') as f:\n",
    "    lines100 = f.read()\n",
    "    \n",
    "with open('../data/lines5000.txt', 'r') as f:\n",
    "    lines5000 = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-13T05:51:59.753803Z",
     "start_time": "2019-08-13T05:51:59.729411Z"
    }
   },
   "outputs": [],
   "source": [
    "tmp = hsplit(lines5000, '.', group=True, attach=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-13T05:51:59.810486Z",
     "start_time": "2019-08-13T05:51:59.761792Z"
    }
   },
   "outputs": [],
   "source": [
    "tmp = hsplit(lines5000, '.', group=False, attach=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-13T05:51:59.827705Z",
     "start_time": "2019-08-13T05:51:59.813883Z"
    }
   },
   "outputs": [],
   "source": [
    "tmp = lines5000.split('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-13T05:51:59.842029Z",
     "start_time": "2019-08-13T05:51:59.832636Z"
    }
   },
   "outputs": [],
   "source": [
    "def hpartition(text, sep):\n",
    "    return text.partition(sep)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
