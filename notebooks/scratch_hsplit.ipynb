{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-13T05:51:59.568535Z",
     "start_time": "2019-08-13T05:51:59.564162Z"
    }
   },
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-13T05:51:59.580396Z",
     "start_time": "2019-08-13T05:51:59.571717Z"
    }
   },
   "outputs": [],
   "source": [
    "def hsplit(text, sep, group=True, attach=True):\n",
    "    \"\"\"Flexible string splitting that retains the delimiter rather, unlike\n",
    "    the built-in str.split() method.\n",
    "    \n",
    "    Parameters\n",
    "    -----------\n",
    "    text: str\n",
    "        The input text to be split.\n",
    "    sep: str\n",
    "        The delimiter to be split on.\n",
    "    group: bool\n",
    "        Specifies whether to group consecutive delimiters together (True),\n",
    "        or to separate them (False).\n",
    "    attach: bool\n",
    "        Specifies whether to attach the delimiter to the string that preceeds \n",
    "        it (True), or to detach it so it appears in the output list as its own \n",
    "        item (False).\n",
    "    \n",
    "    Returns\n",
    "    --------\n",
    "    list[str]\n",
    "    \n",
    "    Examples\n",
    "    ---------\n",
    "    text = \"Score -- Giants win 6-5\"\n",
    "    sep = '-'\n",
    "    \n",
    "    # Case 0.1: Delimiters are grouped together and attached to the preceding \n",
    "    word.\n",
    "    >> hsplit(text, sep, group=True, attach=True)\n",
    "    >> ['Score --', ' Giants win 6-', '5']\n",
    "    \n",
    "    # Case 0.2: Delimiters are grouped together but are detached from the \n",
    "    preceding word, instead appearing as their own item in the output list.\n",
    "    >> hsplit(text, sep, group=True, attach=False)\n",
    "    >> ['Score ', '--', ' Giants win 6', '-', '5']\n",
    "    \n",
    "    Case 1.1: Delimiters are retained and attached to the preceding string. \n",
    "    If the delimiter occurs multiple times consecutively, only the first \n",
    "    occurrence is attached, and the rest appear as individual items in the \n",
    "    output list.\n",
    "    >> hsplit(text, sep, group=False, attach=True)\n",
    "    >> ['Score -', '-', ' Giants win 6-', '5']\n",
    "    \n",
    "    # Case 1.2: Delimiters are retained but are detached from the preceding\n",
    "    string.\n",
    "    It appears as its own item in the output list.\n",
    "    >> hsplit(text, sep, group=False, attach=False)\n",
    "    >> ['Score ', '-', '-', ' Giants win 6', '-', '5']\n",
    "    \"\"\"\n",
    "    sep_re = re.escape(sep)\n",
    "    regex = f'[^{sep_re}]*{sep_re}*'        \n",
    "    \n",
    "    ##########################################################################\n",
    "    # Case 0: Consecutive delimiters are grouped together.\n",
    "    ##########################################################################\n",
    "    if group:\n",
    "        # Subcase 0.1\n",
    "        if attach:\n",
    "            return [word for word in re.findall(regex, text)][:-1]\n",
    "        \n",
    "        # Subcase 0.2\n",
    "        else:\n",
    "            return [word for word in re.split(f'({sep_re}+)', text) if word]\n",
    "    \n",
    "    ##########################################################################\n",
    "    # Case 1: Consecutive delimiters are NOT grouped together.\n",
    "    ##########################################################################\n",
    "    words = text.split(sep)\n",
    "\n",
    "    # Subcase 1.1\n",
    "    if attach:\n",
    "        return [word for word in re.findall(regex[:-1]+'?', text) if word]\n",
    "    \n",
    "    # Subcase 1.2\n",
    "    return [word for word in chain(*zip(words, [sep]*len(words))) if word][:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-13T05:51:59.588756Z",
     "start_time": "2019-08-13T05:51:59.583505Z"
    }
   },
   "outputs": [],
   "source": [
    "text1 = 'I*went to the store* yesterday after* work*to*see* the walrus and it walked slowly* over to me* and sat.'\n",
    "text2 = '*I went*to *the store and* sat next to the window*'\n",
    "text3 = '**I went*to **the store and*** sat next to the window**'\n",
    "\n",
    "texts = [text1, text2, text3]\n",
    "sep = '*'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-13T05:51:59.597631Z",
     "start_time": "2019-08-13T05:51:59.592195Z"
    }
   },
   "outputs": [],
   "source": [
    "def test_output(tests, sep, **kwargs):\n",
    "    for test in tests:\n",
    "        print(test)\n",
    "        print('STANDARD:', test.split(sep))\n",
    "        print('H:', hsplit(test, sep, **kwargs), end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-13T05:51:59.605537Z",
     "start_time": "2019-08-13T05:51:59.599861Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I*went to the store* yesterday after* work*to*see* the walrus and it walked slowly* over to me* and sat.\n",
      "*I went*to *the store and* sat next to the window*\n",
      "**I went*to **the store and*** sat next to the window**\n"
     ]
    }
   ],
   "source": [
    "for text in texts:\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-13T05:51:59.615657Z",
     "start_time": "2019-08-13T05:51:59.608365Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I*went to the store* yesterday after* work*to*see* the walrus and it walked slowly* over to me* and sat.\n",
      "STANDARD: ['I', 'went to the store', ' yesterday after', ' work', 'to', 'see', ' the walrus and it walked slowly', ' over to me', ' and sat.']\n",
      "H: ['I*', 'went to the store*', ' yesterday after*', ' work*', 'to*', 'see*', ' the walrus and it walked slowly*', ' over to me*', ' and sat.']\n",
      "\n",
      "*I went*to *the store and* sat next to the window*\n",
      "STANDARD: ['', 'I went', 'to ', 'the store and', ' sat next to the window', '']\n",
      "H: ['*', 'I went*', 'to *', 'the store and*', ' sat next to the window*']\n",
      "\n",
      "**I went*to **the store and*** sat next to the window**\n",
      "STANDARD: ['', '', 'I went', 'to ', '', 'the store and', '', '', ' sat next to the window', '', '']\n",
      "H: ['**', 'I went*', 'to **', 'the store and***', ' sat next to the window**']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_output(texts, sep, group=True, attach=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-13T05:51:59.649774Z",
     "start_time": "2019-08-13T05:51:59.619447Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I*went to the store* yesterday after* work*to*see* the walrus and it walked slowly* over to me* and sat.\n",
      "STANDARD: ['I', 'went to the store', ' yesterday after', ' work', 'to', 'see', ' the walrus and it walked slowly', ' over to me', ' and sat.']\n",
      "H: ['I', '*', 'went to the store', '*', ' yesterday after', '*', ' work', '*', 'to', '*', 'see', '*', ' the walrus and it walked slowly', '*', ' over to me', '*', ' and sat.']\n",
      "\n",
      "*I went*to *the store and* sat next to the window*\n",
      "STANDARD: ['', 'I went', 'to ', 'the store and', ' sat next to the window', '']\n",
      "H: ['*', 'I went', '*', 'to ', '*', 'the store and', '*', ' sat next to the window', '*']\n",
      "\n",
      "**I went*to **the store and*** sat next to the window**\n",
      "STANDARD: ['', '', 'I went', 'to ', '', 'the store and', '', '', ' sat next to the window', '', '']\n",
      "H: ['**', 'I went', '*', 'to ', '**', 'the store and', '***', ' sat next to the window', '**']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_output(texts, sep, group=True, attach=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-13T05:51:59.685223Z",
     "start_time": "2019-08-13T05:51:59.666834Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I*went to the store* yesterday after* work*to*see* the walrus and it walked slowly* over to me* and sat.\n",
      "STANDARD: ['I', 'went to the store', ' yesterday after', ' work', 'to', 'see', ' the walrus and it walked slowly', ' over to me', ' and sat.']\n",
      "H: ['I*', 'went to the store*', ' yesterday after*', ' work*', 'to*', 'see*', ' the walrus and it walked slowly*', ' over to me*', ' and sat.']\n",
      "\n",
      "*I went*to *the store and* sat next to the window*\n",
      "STANDARD: ['', 'I went', 'to ', 'the store and', ' sat next to the window', '']\n",
      "H: ['*', 'I went*', 'to *', 'the store and*', ' sat next to the window*']\n",
      "\n",
      "**I went*to **the store and*** sat next to the window**\n",
      "STANDARD: ['', '', 'I went', 'to ', '', 'the store and', '', '', ' sat next to the window', '', '']\n",
      "H: ['*', '*', 'I went*', 'to *', '*', 'the store and*', '*', '*', ' sat next to the window*', '*']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_output(texts, sep, group=False, attach=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-13T05:51:59.698200Z",
     "start_time": "2019-08-13T05:51:59.689091Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I*went to the store* yesterday after* work*to*see* the walrus and it walked slowly* over to me* and sat.\n",
      "STANDARD: ['I', 'went to the store', ' yesterday after', ' work', 'to', 'see', ' the walrus and it walked slowly', ' over to me', ' and sat.']\n",
      "H: ['I', '*', 'went to the store', '*', ' yesterday after', '*', ' work', '*', 'to', '*', 'see', '*', ' the walrus and it walked slowly', '*', ' over to me', '*', ' and sat.']\n",
      "\n",
      "*I went*to *the store and* sat next to the window*\n",
      "STANDARD: ['', 'I went', 'to ', 'the store and', ' sat next to the window', '']\n",
      "H: ['*', 'I went', '*', 'to ', '*', 'the store and', '*', ' sat next to the window', '*']\n",
      "\n",
      "**I went*to **the store and*** sat next to the window**\n",
      "STANDARD: ['', '', 'I went', 'to ', '', 'the store and', '', '', ' sat next to the window', '', '']\n",
      "H: ['*', '*', 'I went', '*', 'to ', '*', '*', 'the store and', '*', '*', '*', ' sat next to the window', '*', '*']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_output(texts, sep, group=False, attach=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-13T05:51:59.712686Z",
     "start_time": "2019-08-13T05:51:59.700417Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'went to the store', ' yesterday after', ' work', 'to', 'see', ' the walrus and it walked slowly', ' over to me', ' and sat.']\n",
      "\n",
      "['', 'I went', 'to ', 'the store and', ' sat next to the window', '']\n",
      "\n",
      "['', '', 'I went', 'to ', '', 'the store and', '', '', ' sat next to the window', '', '']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for text in texts:\n",
    "    print(text.split(sep), end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-13T05:51:59.724794Z",
     "start_time": "2019-08-13T05:51:59.715255Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('../data/lines100.txt', 'r') as f:\n",
    "    lines100 = f.read()\n",
    "    \n",
    "with open('../data/lines5000.txt', 'r') as f:\n",
    "    lines5000 = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-13T05:51:59.753803Z",
     "start_time": "2019-08-13T05:51:59.729411Z"
    }
   },
   "outputs": [],
   "source": [
    "tmp = hsplit(lines5000, '.', group=True, attach=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-13T05:51:59.810486Z",
     "start_time": "2019-08-13T05:51:59.761792Z"
    }
   },
   "outputs": [],
   "source": [
    "tmp = hsplit(lines5000, '.', group=False, attach=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-13T05:51:59.827705Z",
     "start_time": "2019-08-13T05:51:59.813883Z"
    }
   },
   "outputs": [],
   "source": [
    "tmp = lines5000.split('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-13T05:51:59.842029Z",
     "start_time": "2019-08-13T05:51:59.832636Z"
    }
   },
   "outputs": [],
   "source": [
    "def hpartition(text, sep):\n",
    "    return text.partition(sep)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
