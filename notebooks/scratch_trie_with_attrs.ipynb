{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Want to eventually add support for trie with word-level and maybe char-level\n",
    "attributes. Ex: word embeddings, word frequencies, char->char transition probs,\n",
    "parts of speech, etc.). Also experimenting with a slightly different interface\n",
    "than the existing trie in htools. Note that names are the same so if you import\n",
    "htools * in a notebook, things may get confusing. Might want to rename these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T20:05:23.108849Z",
     "start_time": "2021-12-29T20:05:20.551088Z"
    }
   },
   "outputs": [],
   "source": [
    "from htools.core import listlike"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T20:09:16.438600Z",
     "start_time": "2021-12-29T20:09:16.414757Z"
    }
   },
   "outputs": [],
   "source": [
    "word_dict = {\n",
    "    'app': 18,\n",
    "    'a': 6,\n",
    "    'apple': 17,\n",
    "    'about': 4,\n",
    "    'able': 6,\n",
    "    'zoo': 13,\n",
    "    'zen': 11,\n",
    "    'zesty': 14,\n",
    "    'apply': 4,\n",
    "    'cow': 18,\n",
    "    'zigzag': 12\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Misc TODOs (still deciding whether to do these)\n",
    "\n",
    "- support for char level features (e.g. prob of transitioning from \"ap\" -> \"app\". Have to think about if that use pattern is common enough to be needed.\n",
    "- support non string seqs like in existing trie\n",
    "- validate inputs like in existing trie\n",
    "- support suffix trie, flip, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T21:19:08.968400Z",
     "start_time": "2021-12-29T21:19:08.916342Z"
    }
   },
   "outputs": [],
   "source": [
    "class TrieNode:\n",
    "\n",
    "    def __init__(self, edges=None, is_terminal=False, is_root=False,\n",
    "                 **kwargs):\n",
    "        self.edges = edges or {}\n",
    "        self.is_terminal = is_terminal\n",
    "        self.is_root = is_root\n",
    "        self.kwarg_names = set(kwargs)\n",
    "        self.set_kwargs(**kwargs)\n",
    "\n",
    "    def set_kwargs(self, **kwargs):\n",
    "        self.kwarg_names.update(kwargs.keys())\n",
    "        self.__dict__.update(**kwargs)\n",
    "        \n",
    "    def get(self, key, default=None):\n",
    "        return self.edges.get(key, default)\n",
    "\n",
    "    def __contains__(self, char):\n",
    "        return char in self.edges\n",
    "\n",
    "    def __getitem__(self, char):\n",
    "        return self.edges[char]\n",
    "\n",
    "    def __setitem__(self, char, val):\n",
    "        self.edges[char] = val\n",
    "        \n",
    "    def __delitem__(self, char):\n",
    "        del self.edges[char]\n",
    "\n",
    "    def __repr__(self):\n",
    "        res = f'TrieNode(edges={list(self.edges)}, '\\\n",
    "              f'is_terminal={self.is_terminal}, ' \\\n",
    "              f'is_root={self.is_root}'\n",
    "        if self.kwarg_names:\n",
    "            kwarg_str = ', '.join(f'{kwarg}={getattr(self, kwarg)}'\n",
    "                                  for kwarg in self.kwarg_names)\n",
    "            res += ', ' + kwarg_str\n",
    "        return res + ')'\n",
    "\n",
    "\n",
    "class Trie:\n",
    "\n",
    "    def __init__(self, vocab=None):\n",
    "        self.root = TrieNode(is_root=True)\n",
    "        # Preview is used in repr. This could become outdated if we delete\n",
    "        # nodes from our trie, however.\n",
    "        self._vocab_preview = []\n",
    "        self._initialize(vocab)\n",
    "\n",
    "    def _initialize(self, vocab):\n",
    "        # Case 1: vocab is list/tuple. Must assign empty kwargs.\n",
    "        if listlike(vocab):\n",
    "            vocab = {word: {} for word in vocab}\n",
    "        # Case 2: vocab is dict but values are not dicts. Assign default name.\n",
    "        elif not isinstance(next(iter(vocab.values())), dict):\n",
    "            vocab = {word: {'val': val} for word, val in vocab.items()}\n",
    "        for i, (word, kwargs) in enumerate(vocab.items()):\n",
    "            if i < 5:\n",
    "                self._vocab_preview.append(word)\n",
    "            self.add(word, **kwargs)\n",
    "            \n",
    "    def _find(self, word, add_missing=False):\n",
    "        node = self.root\n",
    "        for char in word:\n",
    "            if char not in node:\n",
    "                if add_missing:\n",
    "                    node[char] = TrieNode()\n",
    "                else:\n",
    "                    # This is truthy but it means we can always check if the\n",
    "                    # result is_terminal.\n",
    "                    return TrieNode()\n",
    "            node = node[char]\n",
    "        return node\n",
    "\n",
    "    def add(self, word, **kwargs):\n",
    "        # These kwargs are associated with the whole word, e.g. if you want to\n",
    "        # pass in word counts or word embeddings. Still need to implement \n",
    "        # support for character-level attributes if I want that (e.g. if we\n",
    "        # want some kind of transition probability from 1 character to the\n",
    "        # next).\n",
    "        node = self._find(word, add_missing=True)\n",
    "        node.is_terminal = True\n",
    "        node.set_kwargs(**kwargs)\n",
    "\n",
    "    def update(self, words):\n",
    "        for word in words:\n",
    "            self.add(word)\n",
    "            \n",
    "    def path(self, word, func=list.append, start=None):\n",
    "        res = start or []\n",
    "        # TODO: method to accumulate or reduce attrs along the path to a word.\n",
    "        # Current pseudocode relies on unfinished coro/gen method I imagined.\n",
    "        # E.g. the product or sequence of probs of moving from one char/word\n",
    "        # to the next.\n",
    "#         for node in self._iter_nodes(word):\n",
    "#             res = func(res, node) or res\n",
    "#         return res\n",
    "            \n",
    "    def __contains__(self, word):\n",
    "        node = self._find(word, add_missing=False)\n",
    "        return node.is_terminal\n",
    "            \n",
    "    def __repr__(self):\n",
    "        return f'Trie({str(self._vocab_preview)[:-1] + \", ...]\"})'\n",
    "    \n",
    "    # TODO: think about if I like this interface. Currently returns the node\n",
    "    # corresponding to the input word, which is nice for getting word \n",
    "    # attributes. However, it means we can't cast the trie to a list directly.\n",
    "    def __getitem__(self, word):\n",
    "        node = self._find(word, add_missing=False)\n",
    "        if not node.is_terminal:\n",
    "            raise KeyError(f'Key \"{word}\" not found.')\n",
    "        return node\n",
    "    \n",
    "    def __setitem__(self, word, val):\n",
    "        self.add(word, val=val)\n",
    "        \n",
    "    def _keys(self, node=None, seq=None):\n",
    "        node = node or self.root\n",
    "        seq = seq or []\n",
    "        if node.is_terminal:\n",
    "            yield ''.join(seq)\n",
    "        for char, new_node in node.edges.items():\n",
    "            yield from self._keys(self, new_node, seq + [char])\n",
    "            \n",
    "    def keys(self):\n",
    "        return list(self._keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-09T06:44:36.874986Z",
     "start_time": "2022-01-09T06:44:36.820653Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "before send TrieNode(edges=['a', 'z', 'c'], is_terminal=False, is_root=True)\n",
      "after send TrieNode(edges=['p', 'b'], is_terminal=True, is_root=False, val=6)\n",
      "\n",
      "before send TrieNode(edges=['p', 'b'], is_terminal=True, is_root=False, val=6)\n",
      "after send TrieNode(edges=['p'], is_terminal=False, is_root=False)\n",
      "\n",
      "before send TrieNode(edges=['p'], is_terminal=False, is_root=False)\n",
      "after send TrieNode(edges=['l'], is_terminal=True, is_root=False, val=18)\n",
      "\n",
      "before send TrieNode(edges=['l'], is_terminal=True, is_root=False, val=18)\n",
      "after send TrieNode(edges=['e', 'y'], is_terminal=False, is_root=False)\n",
      "\n",
      "before send TrieNode(edges=['e', 'y'], is_terminal=False, is_root=False)\n",
      "after send TrieNode(edges=[], is_terminal=True, is_root=False, val=17)\n",
      "\n",
      "before send TrieNode(edges=[], is_terminal=True, is_root=False, val=17)\n"
     ]
    }
   ],
   "source": [
    "# TODO - eventually want method that yields nodes as we add/search for a new\n",
    "# word. Based on my coroutine/generator pattern. Still debugging.\n",
    "def _find(self, word):\n",
    "    node = self.root\n",
    "    for i, char in enumerate(word):\n",
    "        cur = yield node\n",
    "        if cur:\n",
    "            node = cur.get(char)\n",
    "    # Recall that word of length n involves n+1 nodes, where the last 1 \n",
    "    # is terminal. Note that this node may have edges, e.g. if we have both\n",
    "    # \"app\" and \"apple\" in our trie and try to find the word \"app\".\n",
    "    yield node\n",
    "        \n",
    "t = Trie(word_dict)\n",
    "# print(t)\n",
    "\n",
    "# coro = _find(t, 'apks')\n",
    "# print(next(coro))\n",
    "# for x in coro:\n",
    "#     print('\\nbefore send', x)\n",
    "#     coro.send(x)\n",
    "#     print('after send')\n",
    "\n",
    "# Think this works on words that are present but not those that aren't.\n",
    "coro = _find(t, 'apple')\n",
    "x = next(coro)\n",
    "while True:\n",
    "    try:\n",
    "        print('\\nbefore send', x)\n",
    "        x = coro.send(x)\n",
    "        print('after send', x)\n",
    "    except StopIteration:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T21:17:58.997704Z",
     "start_time": "2021-12-29T21:17:58.968423Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n",
      "app\n",
      "apple\n",
      "apply\n",
      "about\n",
      "able\n",
      "zoo\n",
      "zen\n",
      "zesty\n",
      "zigzag\n",
      "cow\n",
      "dog\n"
     ]
    }
   ],
   "source": [
    "# Broken attempt at iterative _keys() method.\n",
    "# def _dfs(self, node=None):\n",
    "#     \"\"\"\n",
    "#     Traverse trie depth first until we hit a node with no edges.\n",
    "#     At each step, add to our current sequence.\n",
    "#     \"\"\"\n",
    "#     res = []\n",
    "#     stack = [node or self.root]\n",
    "#     cur = []\n",
    "#     while stack:\n",
    "#         node = stack.pop(-1)\n",
    "#         print(node)\n",
    "#         if not node.edges:\n",
    "#             print('TERMINAL', cur)\n",
    "#             cur.clear()\n",
    "#             continue\n",
    "#         for char in node.edges:\n",
    "#             cur.append(char)\n",
    "#         stack.extend(node.edges.values())\n",
    "\n",
    "\n",
    "for word in _dfs(t):\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T21:17:59.329080Z",
     "start_time": "2021-12-29T21:17:59.303538Z"
    }
   },
   "outputs": [],
   "source": [
    "for word in word_dict:\n",
    "    assert word in t, f'Could not find word {word}.'\n",
    "    assert word + 'ZZZ' not in t, f'Found unexpected word {word + \"ZZZ\"}.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T21:17:59.741841Z",
     "start_time": "2021-12-29T21:17:59.718115Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TrieNode(edges=[], is_terminal=True, is_root=False, val=17)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t['apple']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T21:18:00.022521Z",
     "start_time": "2021-12-29T21:17:59.987818Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Key \"dog\" not found.'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-158-d7ce053e8d67>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dog'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-153-91aedd2a7a1b>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, word)\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0mnode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_find\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_terminal\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Key \"{word}\" not found.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Key \"dog\" not found.'"
     ]
    }
   ],
   "source": [
    "t['dog']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T21:18:00.400598Z",
     "start_time": "2021-12-29T21:18:00.375367Z"
    }
   },
   "outputs": [],
   "source": [
    "t['dog'] = 44"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T21:18:00.909268Z",
     "start_time": "2021-12-29T21:18:00.884797Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TrieNode(edges=[], is_terminal=True, is_root=False, val=44)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t['dog']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T21:18:01.198220Z",
     "start_time": "2021-12-29T21:18:01.168218Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'app',\n",
       " 'apple',\n",
       " 'apply',\n",
       " 'about',\n",
       " 'able',\n",
       " 'zoo',\n",
       " 'zen',\n",
       " 'zesty',\n",
       " 'zigzag',\n",
       " 'cow',\n",
       " 'dog']"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-29T21:18:07.812059Z",
     "start_time": "2021-12-29T21:18:07.771587Z"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-162-da10cdbb2773>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-153-91aedd2a7a1b>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, word)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m         \u001b[0mnode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_find\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_terminal\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Key \"{word}\" not found.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-153-91aedd2a7a1b>\u001b[0m in \u001b[0;36m_find\u001b[0;34m(self, word, add_missing)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_find\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mnode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mchar\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mchar\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0madd_missing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object is not iterable"
     ]
    }
   ],
   "source": [
    "list(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
