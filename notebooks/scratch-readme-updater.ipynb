{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T20:47:50.902174Z",
     "start_time": "2021-03-31T20:47:50.865298Z"
    }
   },
   "outputs": [],
   "source": [
    "import ast\n",
    "from collections.abc import Iterable, Mapping\n",
    "from datetime import datetime\n",
    "from itertools import cycle\n",
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import re\n",
    "import subprocess\n",
    "\n",
    "from htools.meta import fallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T21:30:21.935460Z",
     "start_time": "2021-03-31T21:30:21.871198Z"
    }
   },
   "outputs": [],
   "source": [
    "# This is slightly outdated - see cli.py for the final version \n",
    "# (and documentation).\n",
    "class ReadmeUpdater:\n",
    "    \n",
    "    time_fmt = '%Y-%m-%d %H:%M:%S'\n",
    "    readme_id_start = '\\n---\\nStart of auto-generated file data.<br/>'\n",
    "    readme_id_end = '\\n<br/>End of auto-generated file data. Do not add ' \\\n",
    "                    'anything below this.\\n'\n",
    "    readme_regex = readme_id_start + '(.|\\n)*' + readme_id_end\n",
    "    last_edited_cmd_fmt = 'git log -1 --pretty=\"format:%ct\" {}'\n",
    "\n",
    "    def __init__(self, *dirs, default='_'):\n",
    "        self.dirs = [Path(d) for d in dirs]\n",
    "        self.extensions = {'.py', '.ipynb'}\n",
    "        self.default = default\n",
    "\n",
    "    def update_dirs(self, *dirs):\n",
    "        for dir_ in dirs or self.dirs:\n",
    "            file_df = self._parse_dir_files(dir_)\n",
    "            self.update_readme(dir_/'README.md', file_df)\n",
    "\n",
    "    def _parse_dir_files(self, dir_):\n",
    "        files = []\n",
    "        for path in dir_.iterdir():\n",
    "            if path.suffix not in self.extensions: continue\n",
    "            stats = path.stat()\n",
    "            files.append({\n",
    "                'File': path.parts[-1],\n",
    "                'Summary': self.parse_file(path) or self.default,\n",
    "                'Last Modified': self.last_modified_date(path),\n",
    "                'Size': self.readable_file_size(stats.st_size)\n",
    "            })\n",
    "        return pd.DataFrame(files).sort_values('File')\n",
    "\n",
    "    def parse_file(self, path):\n",
    "        return getattr(self, f'_parse_{path.suffix[1:]}')(path)\n",
    "    \n",
    "    def update_readme(self, path, file_df):\n",
    "        path.touch()\n",
    "        with open(path, 'r+') as f:\n",
    "            text = f.read().split(self.readme_id_start)[0] \\\n",
    "                   + self._autogenerate_text(file_df)\n",
    "            f.seek(0)\n",
    "            f.write(text)\n",
    "            \n",
    "    def _autogenerate_text(self, df):\n",
    "        date_str = 'Last updated: ' + datetime.now().strftime(self.time_fmt)\n",
    "        autogen = (self.readme_id_start + date_str + '\\n\\n'\n",
    "                   + df.to_html(index=False).replace('\\\\n', '<br/>') \n",
    "                   + self.readme_id_end)\n",
    "        return autogen\n",
    "\n",
    "    def _parse_py(self, path):\n",
    "        with open(path, 'r') as f:\n",
    "            tree = ast.parse(f.read())\n",
    "        return ast.get_docstring(tree)\n",
    "\n",
    "    def _parse_ipynb(self, path):\n",
    "        with open(path, 'r') as f:\n",
    "            cells = json.load(f)['cells'][:3]\n",
    "        for cell in cells:\n",
    "            if cell['cell_type'] == 'markdown' and \\\n",
    "                    'summary' in cell['source'][0].lower():\n",
    "                # Notebook lines include newlines so we don't add them back in.\n",
    "                return ''.join(cell['source'][1:]).strip()\n",
    "        return ''\n",
    "    \n",
    "    def timestamp_to_time_str(self, time):\n",
    "        return datetime.fromtimestamp(time).strftime(self.time_fmt)\n",
    "    \n",
    "    def last_modified_date(self, path):\n",
    "        try:\n",
    "            # If we're in a git repo, file edit times are changed when we pull\n",
    "            # so we have to use built-in git functionality. This will fail if\n",
    "            # we call the command from a different repo. I vaguely recall \n",
    "            # seeing weird git behavior inside running docker containers so I'm\n",
    "            # not sure if this will work there.\n",
    "            git_time = subprocess.check_output(\n",
    "                self.last_edited_cmd_fmt.format(path).split()\n",
    "            )\n",
    "            timestamp = int(git_time.decode().strip()\n",
    "                                    .replace('format:', '').replace('\"', ''))\n",
    "\n",
    "        except Exception as e:\n",
    "            timestamp = path.stat().st_ctime\n",
    "        return self.timestamp_to_time_str(timestamp)\n",
    "    \n",
    "    @staticmethod\n",
    "    def readable_file_size(n_bytes):\n",
    "        power = len(str(n_bytes)) - 1\n",
    "        assert power < 24, 'Are you sure file is larger than a zettabyte?'\n",
    "\n",
    "        prefix_powers =[\n",
    "            (0, 'b'),\n",
    "            (3, 'kb'),\n",
    "            (6, 'mb'), \n",
    "            (9, 'gb'),\n",
    "            (12, 'tb'),\n",
    "            (15, 'pb'),\n",
    "            (18, 'eb'),\n",
    "            (21, 'zb'),\n",
    "            (24, 'yb')\n",
    "        ]\n",
    "        prev_pow = 0\n",
    "        prev_pre = 'b'\n",
    "        for curr_pow, curr_pre in prefix_powers:\n",
    "            if power < curr_pow: break\n",
    "            prev_pow = curr_pow\n",
    "            prev_pre = curr_pre\n",
    "        return f'{(n_bytes / 10**prev_pow):.2f} {prev_pre}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOTE: ACCIDENTALLY JUST UPDATED ALL v2 READMEs. Check if I want to rollback in git before doing anything else."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T22:16:28.050246Z",
     "start_time": "2021-03-31T22:16:28.021803Z"
    }
   },
   "outputs": [],
   "source": [
    "parser = ReadmeUpdater(\n",
    "    '/Users/harrisonmamin/DatascienceBase/Delphi/v2-0-0/py',\n",
    "    '/Users/harrisonmamin/DatascienceBase/Delphi/v2-0-0/pylib/delphi',\n",
    "    '/Users/harrisonmamin/DatascienceBase/Delphi/v2-0-0/analysis'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T20:49:50.443410Z",
     "start_time": "2021-03-31T20:49:50.417920Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/harrisonmamin/DatascienceBase/Delphi/v2-0-0/py\n",
      "/Users/harrisonmamin/DatascienceBase/Delphi/v2-0-0/pylib\n",
      "/Users/harrisonmamin/DatascienceBase/Delphi/v2-0-0/analysis\n"
     ]
    }
   ],
   "source": [
    "parser.update_dirs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T01:14:06.217421Z",
     "start_time": "2021-03-31T01:14:05.878884Z"
    }
   },
   "outputs": [],
   "source": [
    "df = parser._parse_dir_files(parser.dirs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T01:06:40.710019Z",
     "start_time": "2021-03-31T01:06:40.670602Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last updated: 2021-03-30 18:06:40\n"
     ]
    }
   ],
   "source": [
    "parser.update_readme(Path('../tmp.md'), df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T00:52:45.956610Z",
     "start_time": "2021-03-31T00:52:45.917230Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Last Modified</th>\n",
       "      <th>Created</th>\n",
       "      <th>Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>embeddings_app.py</td>\n",
       "      <td>_</td>\n",
       "      <td>2021-03-29 10:42:30</td>\n",
       "      <td>2021-03-29 10:42:30</td>\n",
       "      <td>12.37 kb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>s00_sync_s3.py</td>\n",
       "      <td>Script to conveniently upload/download files f...</td>\n",
       "      <td>2021-03-29 10:42:30</td>\n",
       "      <td>2021-03-29 10:42:30</td>\n",
       "      <td>2.23 kb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>s01_get_top_domains_entauth.py</td>\n",
       "      <td>_</td>\n",
       "      <td>2021-03-29 10:42:30</td>\n",
       "      <td>2021-03-29 10:42:30</td>\n",
       "      <td>1.78 kb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>s02_scrape_domains.py</td>\n",
       "      <td>_</td>\n",
       "      <td>2021-03-29 10:42:30</td>\n",
       "      <td>2021-03-29 10:42:30</td>\n",
       "      <td>5.14 kb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>s03_process_common_crawl_graph.py</td>\n",
       "      <td>_</td>\n",
       "      <td>2021-03-29 10:42:30</td>\n",
       "      <td>2021-03-29 10:42:30</td>\n",
       "      <td>3.32 kb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>s04_analyze_embeddings.py</td>\n",
       "      <td>This CLI is for analyzing a set of trained emb...</td>\n",
       "      <td>2021-03-29 10:42:30</td>\n",
       "      <td>2021-03-29 10:42:30</td>\n",
       "      <td>4.08 kb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>s05_sample_edgelist.py</td>\n",
       "      <td>_</td>\n",
       "      <td>2021-03-29 10:42:30</td>\n",
       "      <td>2021-03-29 10:42:30</td>\n",
       "      <td>3.20 kb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>s06_train_collab_fastai.py</td>\n",
       "      <td>In progress: train domain embeddings using Fas...</td>\n",
       "      <td>2021-03-29 10:42:30</td>\n",
       "      <td>2021-03-29 10:42:30</td>\n",
       "      <td>2.46 kb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>s07_train_embeddings_incendio.py</td>\n",
       "      <td>_</td>\n",
       "      <td>2021-03-29 10:42:30</td>\n",
       "      <td>2021-03-29 10:42:30</td>\n",
       "      <td>7.17 kb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>s08_build_character_embeddings.py</td>\n",
       "      <td>_</td>\n",
       "      <td>2021-03-29 10:42:30</td>\n",
       "      <td>2021-03-29 10:42:30</td>\n",
       "      <td>3.82 kb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>s09_save_cpu_embeddings.py</td>\n",
       "      <td>Creates cpu-readable pkl files storing domain ...</td>\n",
       "      <td>2021-03-29 10:42:30</td>\n",
       "      <td>2021-03-29 10:42:30</td>\n",
       "      <td>872.00 b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>s10_f8_to_athena.py</td>\n",
       "      <td>_</td>\n",
       "      <td>2021-03-29 10:42:30</td>\n",
       "      <td>2021-03-29 10:42:30</td>\n",
       "      <td>4.18 kb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>s11_merge_scraped_dfs.py</td>\n",
       "      <td>_</td>\n",
       "      <td>2021-03-29 10:42:30</td>\n",
       "      <td>2021-03-29 10:42:30</td>\n",
       "      <td>921.00 b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>s12_make_versioned_data_splits.py</td>\n",
       "      <td>_</td>\n",
       "      <td>2021-03-29 10:42:30</td>\n",
       "      <td>2021-03-29 10:42:30</td>\n",
       "      <td>3.31 kb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>s13_train_log_reg.py</td>\n",
       "      <td>_</td>\n",
       "      <td>2021-03-29 10:42:30</td>\n",
       "      <td>2021-03-29 10:42:30</td>\n",
       "      <td>8.97 kb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>s14_train_fastai.py</td>\n",
       "      <td>_</td>\n",
       "      <td>2021-03-29 10:42:30</td>\n",
       "      <td>2021-03-29 10:42:30</td>\n",
       "      <td>9.88 kb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>s15_format_tf_embeddings.py</td>\n",
       "      <td>_</td>\n",
       "      <td>2021-03-29 10:42:30</td>\n",
       "      <td>2021-03-29 10:42:30</td>\n",
       "      <td>1.69 kb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>s16_predict_for_tf_projector.py</td>\n",
       "      <td>Sample usage:\\n\\npython py/s16_predict_urls   ...</td>\n",
       "      <td>2021-03-29 10:42:30</td>\n",
       "      <td>2021-03-29 10:42:30</td>\n",
       "      <td>2.06 kb</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 File  \\\n",
       "0                   embeddings_app.py   \n",
       "6                      s00_sync_s3.py   \n",
       "10     s01_get_top_domains_entauth.py   \n",
       "17              s02_scrape_domains.py   \n",
       "8   s03_process_common_crawl_graph.py   \n",
       "12          s04_analyze_embeddings.py   \n",
       "7              s05_sample_edgelist.py   \n",
       "1          s06_train_collab_fastai.py   \n",
       "4    s07_train_embeddings_incendio.py   \n",
       "3   s08_build_character_embeddings.py   \n",
       "14         s09_save_cpu_embeddings.py   \n",
       "9                 s10_f8_to_athena.py   \n",
       "11           s11_merge_scraped_dfs.py   \n",
       "5   s12_make_versioned_data_splits.py   \n",
       "2                s13_train_log_reg.py   \n",
       "16                s14_train_fastai.py   \n",
       "15        s15_format_tf_embeddings.py   \n",
       "13    s16_predict_for_tf_projector.py   \n",
       "\n",
       "                                              Summary        Last Modified  \\\n",
       "0                                                   _  2021-03-29 10:42:30   \n",
       "6   Script to conveniently upload/download files f...  2021-03-29 10:42:30   \n",
       "10                                                  _  2021-03-29 10:42:30   \n",
       "17                                                  _  2021-03-29 10:42:30   \n",
       "8                                                   _  2021-03-29 10:42:30   \n",
       "12  This CLI is for analyzing a set of trained emb...  2021-03-29 10:42:30   \n",
       "7                                                   _  2021-03-29 10:42:30   \n",
       "1   In progress: train domain embeddings using Fas...  2021-03-29 10:42:30   \n",
       "4                                                   _  2021-03-29 10:42:30   \n",
       "3                                                   _  2021-03-29 10:42:30   \n",
       "14  Creates cpu-readable pkl files storing domain ...  2021-03-29 10:42:30   \n",
       "9                                                   _  2021-03-29 10:42:30   \n",
       "11                                                  _  2021-03-29 10:42:30   \n",
       "5                                                   _  2021-03-29 10:42:30   \n",
       "2                                                   _  2021-03-29 10:42:30   \n",
       "16                                                  _  2021-03-29 10:42:30   \n",
       "15                                                  _  2021-03-29 10:42:30   \n",
       "13  Sample usage:\\n\\npython py/s16_predict_urls   ...  2021-03-29 10:42:30   \n",
       "\n",
       "                Created      Size  \n",
       "0   2021-03-29 10:42:30  12.37 kb  \n",
       "6   2021-03-29 10:42:30   2.23 kb  \n",
       "10  2021-03-29 10:42:30   1.78 kb  \n",
       "17  2021-03-29 10:42:30   5.14 kb  \n",
       "8   2021-03-29 10:42:30   3.32 kb  \n",
       "12  2021-03-29 10:42:30   4.08 kb  \n",
       "7   2021-03-29 10:42:30   3.20 kb  \n",
       "1   2021-03-29 10:42:30   2.46 kb  \n",
       "4   2021-03-29 10:42:30   7.17 kb  \n",
       "3   2021-03-29 10:42:30   3.82 kb  \n",
       "14  2021-03-29 10:42:30  872.00 b  \n",
       "9   2021-03-29 10:42:30   4.18 kb  \n",
       "11  2021-03-29 10:42:30  921.00 b  \n",
       "5   2021-03-29 10:42:30   3.31 kb  \n",
       "2   2021-03-29 10:42:30   8.97 kb  \n",
       "16  2021-03-29 10:42:30   9.88 kb  \n",
       "15  2021-03-29 10:42:30   1.69 kb  \n",
       "13  2021-03-29 10:42:30   2.06 kb  "
      ]
     },
     "execution_count": 420,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T00:50:56.322089Z",
     "start_time": "2021-03-31T00:50:56.290242Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2021-03-29 10:42:30'"
      ]
     },
     "execution_count": 412,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser.timestamp_to_datetime_str(stats.st_mtime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T00:48:32.346989Z",
     "start_time": "2021-03-31T00:48:32.311055Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>File</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Last Modified</th>\n",
       "      <th>Created</th>\n",
       "      <th>Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>embeddings_app.py</td>\n",
       "      <td>_</td>\n",
       "      <td>2021-03-29</td>\n",
       "      <td>2021-03-29</td>\n",
       "      <td>12.37 kb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>s00_sync_s3.py</td>\n",
       "      <td>Script to conveniently upload/download files from S3.<br/><br/>Examples<br/>--------<br/>python py/s00_sync_s3.py download --all_<br/>python py/s00_sync_s3.py download --only=['data/misc/']<br/>python py/s00_sync_s3.py download --exclude=['data/scraped/']</td>\n",
       "      <td>2021-03-29</td>\n",
       "      <td>2021-03-29</td>\n",
       "      <td>2.23 kb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>s01_get_top_domains_entauth.py</td>\n",
       "      <td>_</td>\n",
       "      <td>2021-03-29</td>\n",
       "      <td>2021-03-29</td>\n",
       "      <td>1.78 kb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>s02_scrape_domains.py</td>\n",
       "      <td>_</td>\n",
       "      <td>2021-03-29</td>\n",
       "      <td>2021-03-29</td>\n",
       "      <td>5.14 kb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>s03_process_common_crawl_graph.py</td>\n",
       "      <td>_</td>\n",
       "      <td>2021-03-29</td>\n",
       "      <td>2021-03-29</td>\n",
       "      <td>3.32 kb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>s04_analyze_embeddings.py</td>\n",
       "      <td>This CLI is for analyzing a set of trained embeddings, but it needs to be<br/>updated (currently uses the old version of the Embeddings class). <br/>In the mean time, analysis should be done through the embeddings dash app in<br/>this same directory.</td>\n",
       "      <td>2021-03-29</td>\n",
       "      <td>2021-03-29</td>\n",
       "      <td>4.08 kb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>s05_sample_edgelist.py</td>\n",
       "      <td>_</td>\n",
       "      <td>2021-03-29</td>\n",
       "      <td>2021-03-29</td>\n",
       "      <td>3.20 kb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>s06_train_collab_fastai.py</td>\n",
       "      <td>In progress: train domain embeddings using FastAI collaborative<br/>filtering.</td>\n",
       "      <td>2021-03-29</td>\n",
       "      <td>2021-03-29</td>\n",
       "      <td>2.46 kb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>s07_train_embeddings_incendio.py</td>\n",
       "      <td>_</td>\n",
       "      <td>2021-03-29</td>\n",
       "      <td>2021-03-29</td>\n",
       "      <td>7.17 kb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>s08_build_character_embeddings.py</td>\n",
       "      <td>_</td>\n",
       "      <td>2021-03-29</td>\n",
       "      <td>2021-03-29</td>\n",
       "      <td>3.82 kb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>s09_save_cpu_embeddings.py</td>\n",
       "      <td>Creates cpu-readable pkl files storing domain embeddings as numpy arrays.<br/>In the future this will hopefully be unnecessary, but these domain embeddings<br/>were trained with incendio 0.0.21 which had some issues with loading and<br/>saving. Files are also uploaded to s3.</td>\n",
       "      <td>2021-03-29</td>\n",
       "      <td>2021-03-29</td>\n",
       "      <td>872.00 b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>s10_f8_to_athena.py</td>\n",
       "      <td>_</td>\n",
       "      <td>2021-03-29</td>\n",
       "      <td>2021-03-29</td>\n",
       "      <td>4.18 kb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>s11_merge_scraped_dfs.py</td>\n",
       "      <td>_</td>\n",
       "      <td>2021-03-29</td>\n",
       "      <td>2021-03-29</td>\n",
       "      <td>921.00 b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>s12_make_versioned_data_splits.py</td>\n",
       "      <td>_</td>\n",
       "      <td>2021-03-29</td>\n",
       "      <td>2021-03-29</td>\n",
       "      <td>3.31 kb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>s13_train_log_reg.py</td>\n",
       "      <td>_</td>\n",
       "      <td>2021-03-29</td>\n",
       "      <td>2021-03-29</td>\n",
       "      <td>8.97 kb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>s14_train_fastai.py</td>\n",
       "      <td>_</td>\n",
       "      <td>2021-03-29</td>\n",
       "      <td>2021-03-29</td>\n",
       "      <td>9.88 kb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>s15_format_tf_embeddings.py</td>\n",
       "      <td>_</td>\n",
       "      <td>2021-03-29</td>\n",
       "      <td>2021-03-29</td>\n",
       "      <td>1.69 kb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>s16_predict_for_tf_projector.py</td>\n",
       "      <td>Sample usage:<br/><br/>python py/s16_predict_urls     --url_path data/domain_embeddings/v2/embeddings_meta.txt</td>\n",
       "      <td>2021-03-29</td>\n",
       "      <td>2021-03-29</td>\n",
       "      <td>2.06 kb</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from IPython.display import HTML\n",
    "# display(HTML(df.to_html(index=False)))\n",
    "display(HTML(df.to_html(index=False).replace('\\\\n', '<br/>')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-30T23:31:03.586787Z",
     "start_time": "2021-03-30T23:31:03.555712Z"
    }
   },
   "outputs": [],
   "source": [
    "def readable_file_size(n_bytes):\n",
    "    power = len(str(n_bytes)) - 1\n",
    "    assert power < 24, 'Are you sure file is larger than a zettabyte?'\n",
    "    \n",
    "    prefix_powers =[\n",
    "        (0, 'b'),\n",
    "        (3, 'kb'),\n",
    "        (6, 'mb'), \n",
    "        (9, 'gb'),\n",
    "        (12, 'tb'),\n",
    "        (15, 'pb'),\n",
    "        (18, 'eb'),\n",
    "        (21, 'zb'),\n",
    "        (24, 'yb')\n",
    "    ]\n",
    "    prev_pow = 0\n",
    "    prev_pre = 'b'\n",
    "    for curr_pow, curr_pre in prefix_powers:\n",
    "        if power < curr_pow: break\n",
    "        prev_pow = curr_pow\n",
    "        prev_pre = curr_pre\n",
    "    return f'{(n_bytes / 10**prev_pow):.2f} {prev_pre}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-30T23:31:11.561838Z",
     "start_time": "2021-03-30T23:31:11.514147Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1 1.00 b\n",
      "2 12 12.00 b\n",
      "3 123 123.00 b\n",
      "4 1234 1.23 kb\n",
      "5 12345 12.35 kb\n",
      "6 123456 123.46 kb\n",
      "7 1234567 1.23 mb\n",
      "8 12345678 12.35 mb\n",
      "9 123456789 123.46 mb\n",
      "10 1234567891 1.23 gb\n",
      "11 12345678912 12.35 gb\n",
      "12 123456789123 123.46 gb\n",
      "13 1234567891234 1.23 tb\n",
      "14 12345678912345 12.35 tb\n",
      "15 123456789123456 123.46 tb\n",
      "16 1234567891234567 1.23 pb\n",
      "17 12345678912345678 12.35 pb\n",
      "18 123456789123456789 123.46 pb\n",
      "19 1234567891234567891 1.23 eb\n",
      "20 12345678912345678912 12.35 eb\n",
      "21 123456789123456789123 123.46 eb\n",
      "22 1234567891234567891234 1.23 zb\n",
      "23 12345678912345678912345 12.35 zb\n",
      "24 123456789123456789123456 123.46 zb\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Are you sure file is larger than a zettabyte?",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-212-b73462b2c504>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mlength\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mcurr\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadable_file_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-211-574703fbbe0a>\u001b[0m in \u001b[0;36mreadable_file_size\u001b[0;34m(n_bytes)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mreadable_file_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mpower\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0mpower\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m24\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Are you sure file is larger than a zettabyte?'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     prefix_powers =[\n",
      "\u001b[0;31mAssertionError\u001b[0m: Are you sure file is larger than a zettabyte?"
     ]
    }
   ],
   "source": [
    "for length in range(1, 26):\n",
    "    range_ = cycle(range(1, 10))\n",
    "    curr = ''\n",
    "    while len(curr) < length:\n",
    "        curr += str(next(range_))\n",
    "    print(length, curr, readable_file_size(int(curr)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
