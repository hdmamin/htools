{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T00:56:34.778396Z",
     "start_time": "2021-03-31T00:56:34.748007Z"
    }
   },
   "outputs": [],
   "source": [
    "import ast\n",
    "from collections.abc import Iterable, Mapping\n",
    "from datetime import datetime\n",
    "from itertools import cycle\n",
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import re\n",
    "import subprocess\n",
    "\n",
    "from htools.core import save, load, item, shell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T01:23:31.474961Z",
     "start_time": "2021-03-31T01:23:31.418651Z"
    }
   },
   "outputs": [],
   "source": [
    "class ReadmeUpdater:\n",
    "    \n",
    "    time_fmt = '%Y-%m-%d %H:%M:%S'\n",
    "    readme_id_start = '---\\nStart of auto-generated file data.<br/>'\n",
    "    readme_id_end = '\\n<br/>End of auto-generated file data. Do not add ' \\\n",
    "                    'anything below this.\\n'\n",
    "    readme_regex = readme_id_start + '(.|\\n)*' + readme_id_end\n",
    "    last_edited_cmd_fmt = 'git log -1 --pretty=\"format:%ct\" {}'\n",
    "\n",
    "    def __init__(self, dirs, default='_'):\n",
    "        self.dirs = [Path(d) for d in dirs]\n",
    "        self.extensions = {'.py', '.ipynb'}\n",
    "        self.default = default\n",
    "\n",
    "    def parse_files(self):\n",
    "        for dir_ in self.dirs:\n",
    "            file_df = self._process_dir_files(dir_)\n",
    "            self.update_readme(dir_/'README.md', file_df)\n",
    "\n",
    "    def _parse_dir_files(self, dir_):\n",
    "        files = []\n",
    "        for path in dir_.iterdir():\n",
    "            if path.suffix not in self.extensions: continue\n",
    "            stats = path.stat()\n",
    "            files.append({\n",
    "                'File': path.parts[-1],\n",
    "                'Summary': self.parse_file(path) or self.default,\n",
    "                'Last Modified': self.last_modified_date(path),\n",
    "                'Size': self.readable_file_size(stats.st_size)\n",
    "            })\n",
    "        return pd.DataFrame(files).sort_values('File')\n",
    "\n",
    "    def parse_file(self, path):\n",
    "        return getattr(self, f'_parse_{path.suffix[1:]}')(path)\n",
    "    \n",
    "    def update_readme(self, path, file_df):\n",
    "        path.touch()\n",
    "        with open(path, 'r+') as f:\n",
    "            text = f.read().split(self.readme_id_start)[0] \\\n",
    "                   + self._autogenerate_text(file_df)\n",
    "            f.seek(0)\n",
    "            f.write(text)\n",
    "            \n",
    "    def _autogenerate_text(self, df):\n",
    "        date_str = 'Last updated: ' + datetime.now().strftime(self.time_fmt)\n",
    "        autogen = (self.readme_id_start + date_str + '\\n\\n'\n",
    "                   + df.to_html(index=False).replace('\\\\n', '<br/>') \n",
    "                   + self.readme_id_end)\n",
    "        return autogen\n",
    "\n",
    "    def _parse_py(self, path):\n",
    "        with open(path, 'r') as f:\n",
    "            tree = ast.parse(f.read())\n",
    "        return ast.get_docstring(tree)\n",
    "\n",
    "    def _parse_ipynb(self, path):\n",
    "        with open(path, 'r') as f:\n",
    "            cells = json.load(f)['cells'][:3]\n",
    "        for cell in cells:\n",
    "            if cell['cell_type'] == 'markdown' and \\\n",
    "                    'summary' in cell['source'][0].lower():\n",
    "                return '\\n'.join(cell['source'][1:]).strip()\n",
    "        return ''\n",
    "    \n",
    "    def timestamp_to_time_str(self, time):\n",
    "        return datetime.fromtimestamp(time).strftime(self.time_fmt)\n",
    "    \n",
    "    def last_modified_date(self, path):\n",
    "        try:\n",
    "            # If we're in a git repo, file edit times are changed when we pull\n",
    "            # so we have to use built-in git functionality. This will fail if\n",
    "            # we call the command from a different repo. I vaguely recall \n",
    "            # seeing weird git behavior inside running docker containers so I'm\n",
    "            # not sure if this will work there.\n",
    "            timestamp = subprocess.check_output(\n",
    "                self.last_edited_cmd_fmt.format(path).split()\n",
    "            ).decode().strip().replace('format:', '').replace('\"', '')\n",
    "        except Exception as e:\n",
    "            timestamp = path.stat().st_ctime\n",
    "        return self.timestamp_to_time_str(timestamp)\n",
    "    \n",
    "    @staticmethod\n",
    "    def readable_file_size(n_bytes):\n",
    "        power = len(str(n_bytes)) - 1\n",
    "        assert power < 24, 'Are you sure file is larger than a zettabyte?'\n",
    "\n",
    "        prefix_powers =[\n",
    "            (0, 'b'),\n",
    "            (3, 'kb'),\n",
    "            (6, 'mb'), \n",
    "            (9, 'gb'),\n",
    "            (12, 'tb'),\n",
    "            (15, 'pb'),\n",
    "            (18, 'eb'),\n",
    "            (21, 'zb'),\n",
    "            (24, 'yb')\n",
    "        ]\n",
    "        prev_pow = 0\n",
    "        prev_pre = 'b'\n",
    "        for curr_pow, curr_pre in prefix_powers:\n",
    "            if power < curr_pow: break\n",
    "            prev_pow = curr_pow\n",
    "            prev_pre = curr_pre\n",
    "        return f'{(n_bytes / 10**prev_pow):.2f} {prev_pre}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T01:21:46.744291Z",
     "start_time": "2021-03-31T01:21:46.719076Z"
    }
   },
   "outputs": [],
   "source": [
    "parser = ReadmeUpdater(\n",
    "    ['/Users/harrisonmamin/DatascienceBase/Delphi/v2-0-0/py',\n",
    "     '/Users/harrisonmamin/DatascienceBase/Delphi/v2-0-0/pylib',\n",
    "     '/Users/harrisonmamin/DatascienceBase/Delphi/v2-0-0/analysis']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T01:14:06.217421Z",
     "start_time": "2021-03-31T01:14:05.878884Z"
    }
   },
   "outputs": [],
   "source": [
    "df = parser._parse_dir_files(parser.dirs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T01:06:40.710019Z",
     "start_time": "2021-03-31T01:06:40.670602Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last updated: 2021-03-30 18:06:40\n"
     ]
    }
   ],
   "source": [
    "parser.update_readme(Path('../tmp.md'), df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T00:52:45.956610Z",
     "start_time": "2021-03-31T00:52:45.917230Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Last Modified</th>\n",
       "      <th>Created</th>\n",
       "      <th>Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>embeddings_app.py</td>\n",
       "      <td>_</td>\n",
       "      <td>2021-03-29 10:42:30</td>\n",
       "      <td>2021-03-29 10:42:30</td>\n",
       "      <td>12.37 kb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>s00_sync_s3.py</td>\n",
       "      <td>Script to conveniently upload/download files f...</td>\n",
       "      <td>2021-03-29 10:42:30</td>\n",
       "      <td>2021-03-29 10:42:30</td>\n",
       "      <td>2.23 kb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>s01_get_top_domains_entauth.py</td>\n",
       "      <td>_</td>\n",
       "      <td>2021-03-29 10:42:30</td>\n",
       "      <td>2021-03-29 10:42:30</td>\n",
       "      <td>1.78 kb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>s02_scrape_domains.py</td>\n",
       "      <td>_</td>\n",
       "      <td>2021-03-29 10:42:30</td>\n",
       "      <td>2021-03-29 10:42:30</td>\n",
       "      <td>5.14 kb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>s03_process_common_crawl_graph.py</td>\n",
       "      <td>_</td>\n",
       "      <td>2021-03-29 10:42:30</td>\n",
       "      <td>2021-03-29 10:42:30</td>\n",
       "      <td>3.32 kb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>s04_analyze_embeddings.py</td>\n",
       "      <td>This CLI is for analyzing a set of trained emb...</td>\n",
       "      <td>2021-03-29 10:42:30</td>\n",
       "      <td>2021-03-29 10:42:30</td>\n",
       "      <td>4.08 kb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>s05_sample_edgelist.py</td>\n",
       "      <td>_</td>\n",
       "      <td>2021-03-29 10:42:30</td>\n",
       "      <td>2021-03-29 10:42:30</td>\n",
       "      <td>3.20 kb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>s06_train_collab_fastai.py</td>\n",
       "      <td>In progress: train domain embeddings using Fas...</td>\n",
       "      <td>2021-03-29 10:42:30</td>\n",
       "      <td>2021-03-29 10:42:30</td>\n",
       "      <td>2.46 kb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>s07_train_embeddings_incendio.py</td>\n",
       "      <td>_</td>\n",
       "      <td>2021-03-29 10:42:30</td>\n",
       "      <td>2021-03-29 10:42:30</td>\n",
       "      <td>7.17 kb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>s08_build_character_embeddings.py</td>\n",
       "      <td>_</td>\n",
       "      <td>2021-03-29 10:42:30</td>\n",
       "      <td>2021-03-29 10:42:30</td>\n",
       "      <td>3.82 kb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>s09_save_cpu_embeddings.py</td>\n",
       "      <td>Creates cpu-readable pkl files storing domain ...</td>\n",
       "      <td>2021-03-29 10:42:30</td>\n",
       "      <td>2021-03-29 10:42:30</td>\n",
       "      <td>872.00 b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>s10_f8_to_athena.py</td>\n",
       "      <td>_</td>\n",
       "      <td>2021-03-29 10:42:30</td>\n",
       "      <td>2021-03-29 10:42:30</td>\n",
       "      <td>4.18 kb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>s11_merge_scraped_dfs.py</td>\n",
       "      <td>_</td>\n",
       "      <td>2021-03-29 10:42:30</td>\n",
       "      <td>2021-03-29 10:42:30</td>\n",
       "      <td>921.00 b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>s12_make_versioned_data_splits.py</td>\n",
       "      <td>_</td>\n",
       "      <td>2021-03-29 10:42:30</td>\n",
       "      <td>2021-03-29 10:42:30</td>\n",
       "      <td>3.31 kb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>s13_train_log_reg.py</td>\n",
       "      <td>_</td>\n",
       "      <td>2021-03-29 10:42:30</td>\n",
       "      <td>2021-03-29 10:42:30</td>\n",
       "      <td>8.97 kb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>s14_train_fastai.py</td>\n",
       "      <td>_</td>\n",
       "      <td>2021-03-29 10:42:30</td>\n",
       "      <td>2021-03-29 10:42:30</td>\n",
       "      <td>9.88 kb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>s15_format_tf_embeddings.py</td>\n",
       "      <td>_</td>\n",
       "      <td>2021-03-29 10:42:30</td>\n",
       "      <td>2021-03-29 10:42:30</td>\n",
       "      <td>1.69 kb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>s16_predict_for_tf_projector.py</td>\n",
       "      <td>Sample usage:\\n\\npython py/s16_predict_urls   ...</td>\n",
       "      <td>2021-03-29 10:42:30</td>\n",
       "      <td>2021-03-29 10:42:30</td>\n",
       "      <td>2.06 kb</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 File  \\\n",
       "0                   embeddings_app.py   \n",
       "6                      s00_sync_s3.py   \n",
       "10     s01_get_top_domains_entauth.py   \n",
       "17              s02_scrape_domains.py   \n",
       "8   s03_process_common_crawl_graph.py   \n",
       "12          s04_analyze_embeddings.py   \n",
       "7              s05_sample_edgelist.py   \n",
       "1          s06_train_collab_fastai.py   \n",
       "4    s07_train_embeddings_incendio.py   \n",
       "3   s08_build_character_embeddings.py   \n",
       "14         s09_save_cpu_embeddings.py   \n",
       "9                 s10_f8_to_athena.py   \n",
       "11           s11_merge_scraped_dfs.py   \n",
       "5   s12_make_versioned_data_splits.py   \n",
       "2                s13_train_log_reg.py   \n",
       "16                s14_train_fastai.py   \n",
       "15        s15_format_tf_embeddings.py   \n",
       "13    s16_predict_for_tf_projector.py   \n",
       "\n",
       "                                              Summary        Last Modified  \\\n",
       "0                                                   _  2021-03-29 10:42:30   \n",
       "6   Script to conveniently upload/download files f...  2021-03-29 10:42:30   \n",
       "10                                                  _  2021-03-29 10:42:30   \n",
       "17                                                  _  2021-03-29 10:42:30   \n",
       "8                                                   _  2021-03-29 10:42:30   \n",
       "12  This CLI is for analyzing a set of trained emb...  2021-03-29 10:42:30   \n",
       "7                                                   _  2021-03-29 10:42:30   \n",
       "1   In progress: train domain embeddings using Fas...  2021-03-29 10:42:30   \n",
       "4                                                   _  2021-03-29 10:42:30   \n",
       "3                                                   _  2021-03-29 10:42:30   \n",
       "14  Creates cpu-readable pkl files storing domain ...  2021-03-29 10:42:30   \n",
       "9                                                   _  2021-03-29 10:42:30   \n",
       "11                                                  _  2021-03-29 10:42:30   \n",
       "5                                                   _  2021-03-29 10:42:30   \n",
       "2                                                   _  2021-03-29 10:42:30   \n",
       "16                                                  _  2021-03-29 10:42:30   \n",
       "15                                                  _  2021-03-29 10:42:30   \n",
       "13  Sample usage:\\n\\npython py/s16_predict_urls   ...  2021-03-29 10:42:30   \n",
       "\n",
       "                Created      Size  \n",
       "0   2021-03-29 10:42:30  12.37 kb  \n",
       "6   2021-03-29 10:42:30   2.23 kb  \n",
       "10  2021-03-29 10:42:30   1.78 kb  \n",
       "17  2021-03-29 10:42:30   5.14 kb  \n",
       "8   2021-03-29 10:42:30   3.32 kb  \n",
       "12  2021-03-29 10:42:30   4.08 kb  \n",
       "7   2021-03-29 10:42:30   3.20 kb  \n",
       "1   2021-03-29 10:42:30   2.46 kb  \n",
       "4   2021-03-29 10:42:30   7.17 kb  \n",
       "3   2021-03-29 10:42:30   3.82 kb  \n",
       "14  2021-03-29 10:42:30  872.00 b  \n",
       "9   2021-03-29 10:42:30   4.18 kb  \n",
       "11  2021-03-29 10:42:30  921.00 b  \n",
       "5   2021-03-29 10:42:30   3.31 kb  \n",
       "2   2021-03-29 10:42:30   8.97 kb  \n",
       "16  2021-03-29 10:42:30   9.88 kb  \n",
       "15  2021-03-29 10:42:30   1.69 kb  \n",
       "13  2021-03-29 10:42:30   2.06 kb  "
      ]
     },
     "execution_count": 420,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T00:50:56.322089Z",
     "start_time": "2021-03-31T00:50:56.290242Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2021-03-29 10:42:30'"
      ]
     },
     "execution_count": 412,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser.timestamp_to_datetime_str(stats.st_mtime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T00:48:32.346989Z",
     "start_time": "2021-03-31T00:48:32.311055Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>File</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Last Modified</th>\n",
       "      <th>Created</th>\n",
       "      <th>Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>embeddings_app.py</td>\n",
       "      <td>_</td>\n",
       "      <td>2021-03-29</td>\n",
       "      <td>2021-03-29</td>\n",
       "      <td>12.37 kb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>s00_sync_s3.py</td>\n",
       "      <td>Script to conveniently upload/download files from S3.<br/><br/>Examples<br/>--------<br/>python py/s00_sync_s3.py download --all_<br/>python py/s00_sync_s3.py download --only=['data/misc/']<br/>python py/s00_sync_s3.py download --exclude=['data/scraped/']</td>\n",
       "      <td>2021-03-29</td>\n",
       "      <td>2021-03-29</td>\n",
       "      <td>2.23 kb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>s01_get_top_domains_entauth.py</td>\n",
       "      <td>_</td>\n",
       "      <td>2021-03-29</td>\n",
       "      <td>2021-03-29</td>\n",
       "      <td>1.78 kb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>s02_scrape_domains.py</td>\n",
       "      <td>_</td>\n",
       "      <td>2021-03-29</td>\n",
       "      <td>2021-03-29</td>\n",
       "      <td>5.14 kb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>s03_process_common_crawl_graph.py</td>\n",
       "      <td>_</td>\n",
       "      <td>2021-03-29</td>\n",
       "      <td>2021-03-29</td>\n",
       "      <td>3.32 kb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>s04_analyze_embeddings.py</td>\n",
       "      <td>This CLI is for analyzing a set of trained embeddings, but it needs to be<br/>updated (currently uses the old version of the Embeddings class). <br/>In the mean time, analysis should be done through the embeddings dash app in<br/>this same directory.</td>\n",
       "      <td>2021-03-29</td>\n",
       "      <td>2021-03-29</td>\n",
       "      <td>4.08 kb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>s05_sample_edgelist.py</td>\n",
       "      <td>_</td>\n",
       "      <td>2021-03-29</td>\n",
       "      <td>2021-03-29</td>\n",
       "      <td>3.20 kb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>s06_train_collab_fastai.py</td>\n",
       "      <td>In progress: train domain embeddings using FastAI collaborative<br/>filtering.</td>\n",
       "      <td>2021-03-29</td>\n",
       "      <td>2021-03-29</td>\n",
       "      <td>2.46 kb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>s07_train_embeddings_incendio.py</td>\n",
       "      <td>_</td>\n",
       "      <td>2021-03-29</td>\n",
       "      <td>2021-03-29</td>\n",
       "      <td>7.17 kb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>s08_build_character_embeddings.py</td>\n",
       "      <td>_</td>\n",
       "      <td>2021-03-29</td>\n",
       "      <td>2021-03-29</td>\n",
       "      <td>3.82 kb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>s09_save_cpu_embeddings.py</td>\n",
       "      <td>Creates cpu-readable pkl files storing domain embeddings as numpy arrays.<br/>In the future this will hopefully be unnecessary, but these domain embeddings<br/>were trained with incendio 0.0.21 which had some issues with loading and<br/>saving. Files are also uploaded to s3.</td>\n",
       "      <td>2021-03-29</td>\n",
       "      <td>2021-03-29</td>\n",
       "      <td>872.00 b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>s10_f8_to_athena.py</td>\n",
       "      <td>_</td>\n",
       "      <td>2021-03-29</td>\n",
       "      <td>2021-03-29</td>\n",
       "      <td>4.18 kb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>s11_merge_scraped_dfs.py</td>\n",
       "      <td>_</td>\n",
       "      <td>2021-03-29</td>\n",
       "      <td>2021-03-29</td>\n",
       "      <td>921.00 b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>s12_make_versioned_data_splits.py</td>\n",
       "      <td>_</td>\n",
       "      <td>2021-03-29</td>\n",
       "      <td>2021-03-29</td>\n",
       "      <td>3.31 kb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>s13_train_log_reg.py</td>\n",
       "      <td>_</td>\n",
       "      <td>2021-03-29</td>\n",
       "      <td>2021-03-29</td>\n",
       "      <td>8.97 kb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>s14_train_fastai.py</td>\n",
       "      <td>_</td>\n",
       "      <td>2021-03-29</td>\n",
       "      <td>2021-03-29</td>\n",
       "      <td>9.88 kb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>s15_format_tf_embeddings.py</td>\n",
       "      <td>_</td>\n",
       "      <td>2021-03-29</td>\n",
       "      <td>2021-03-29</td>\n",
       "      <td>1.69 kb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>s16_predict_for_tf_projector.py</td>\n",
       "      <td>Sample usage:<br/><br/>python py/s16_predict_urls     --url_path data/domain_embeddings/v2/embeddings_meta.txt</td>\n",
       "      <td>2021-03-29</td>\n",
       "      <td>2021-03-29</td>\n",
       "      <td>2.06 kb</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from IPython.display import HTML\n",
    "# display(HTML(df.to_html(index=False)))\n",
    "display(HTML(df.to_html(index=False).replace('\\\\n', '<br/>')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-30T23:31:03.586787Z",
     "start_time": "2021-03-30T23:31:03.555712Z"
    }
   },
   "outputs": [],
   "source": [
    "def readable_file_size(n_bytes):\n",
    "    power = len(str(n_bytes)) - 1\n",
    "    assert power < 24, 'Are you sure file is larger than a zettabyte?'\n",
    "    \n",
    "    prefix_powers =[\n",
    "        (0, 'b'),\n",
    "        (3, 'kb'),\n",
    "        (6, 'mb'), \n",
    "        (9, 'gb'),\n",
    "        (12, 'tb'),\n",
    "        (15, 'pb'),\n",
    "        (18, 'eb'),\n",
    "        (21, 'zb'),\n",
    "        (24, 'yb')\n",
    "    ]\n",
    "    prev_pow = 0\n",
    "    prev_pre = 'b'\n",
    "    for curr_pow, curr_pre in prefix_powers:\n",
    "        if power < curr_pow: break\n",
    "        prev_pow = curr_pow\n",
    "        prev_pre = curr_pre\n",
    "    return f'{(n_bytes / 10**prev_pow):.2f} {prev_pre}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-30T23:31:11.561838Z",
     "start_time": "2021-03-30T23:31:11.514147Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1 1.00 b\n",
      "2 12 12.00 b\n",
      "3 123 123.00 b\n",
      "4 1234 1.23 kb\n",
      "5 12345 12.35 kb\n",
      "6 123456 123.46 kb\n",
      "7 1234567 1.23 mb\n",
      "8 12345678 12.35 mb\n",
      "9 123456789 123.46 mb\n",
      "10 1234567891 1.23 gb\n",
      "11 12345678912 12.35 gb\n",
      "12 123456789123 123.46 gb\n",
      "13 1234567891234 1.23 tb\n",
      "14 12345678912345 12.35 tb\n",
      "15 123456789123456 123.46 tb\n",
      "16 1234567891234567 1.23 pb\n",
      "17 12345678912345678 12.35 pb\n",
      "18 123456789123456789 123.46 pb\n",
      "19 1234567891234567891 1.23 eb\n",
      "20 12345678912345678912 12.35 eb\n",
      "21 123456789123456789123 123.46 eb\n",
      "22 1234567891234567891234 1.23 zb\n",
      "23 12345678912345678912345 12.35 zb\n",
      "24 123456789123456789123456 123.46 zb\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Are you sure file is larger than a zettabyte?",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-212-b73462b2c504>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mlength\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mcurr\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadable_file_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-211-574703fbbe0a>\u001b[0m in \u001b[0;36mreadable_file_size\u001b[0;34m(n_bytes)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mreadable_file_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mpower\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0mpower\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m24\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Are you sure file is larger than a zettabyte?'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     prefix_powers =[\n",
      "\u001b[0;31mAssertionError\u001b[0m: Are you sure file is larger than a zettabyte?"
     ]
    }
   ],
   "source": [
    "for length in range(1, 26):\n",
    "    range_ = cycle(range(1, 10))\n",
    "    curr = ''\n",
    "    while len(curr) < length:\n",
    "        curr += str(next(range_))\n",
    "    print(length, curr, readable_file_size(int(curr)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
